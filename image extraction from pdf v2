import fitz           # PyMuPDF
import cv2
import numpy as np
import os
from PIL import Image
import pytesseract
from pytesseract import Output
import re

# Set this if Tesseract is not in PATH (for Windows)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# === SETTINGS ===
input_folder = r"C:\Users\menha\Downloads\test11"
output_folder = os.path.join(input_folder, "extracted_diagrams_fixed")
os.makedirs(output_folder, exist_ok=True)

zoom = 3.5
base_pad = 15
min_area = 3000

# === IMPROVED QUESTION NUMBER EXTRACTION ===
def extract_question_numbers_from_page(page):
    """Extract ALL question numbers from the page text with AGGRESSIVE patterns."""
    text = page.get_text()
    question_numbers = []
    
    print(f"    Raw text preview: {text[:200]}...")  # Debug
    
    # MORE AGGRESSIVE patterns for GATE exam format
    patterns = [
        # Most common: Q.19, Q.20, etc.
        r'Q\.\s*(\d+)',
        # Q19, Q20 (without dot)
        r'Q\s*(\d+)',
        # Question 19, Question 20
        r'Question\s*(\d+)',
        # Q.19) or Q.19.
        r'Q\.\s*(\d+)\)',
        r'Q\.\s*(\d+)\.',
        # In parentheses (Q.19) or (19)
        r'\(\s*Q\.\s*(\d+)\s*\)',
        r'\(\s*(\d+)\s*\)',
        # At start of line: 19. 
        r'^\s*(\d+)\.',
        # Q-19, Q - 19
        r'Q\s*-\s*(\d+)',
        # Q.19: or Q.19-
        r'Q\.\s*(\d+)\:',
        r'Q\.\s*(\d+)\-',
        # Common in questions: "19." at line start
        r'\n\s*(\d+)\.',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            if match.isdigit():
                q_num = f"Q{match}"
                if q_num not in question_numbers:
                    question_numbers.append(q_num)
                    print(f"    Found pattern '{pattern}': {q_num}")  # Debug
    
    # Also try to extract from the raw text lines - MORE AGGRESSIVE
    lines = text.split('\n')
    for i, line in enumerate(lines):
        line = line.strip()
        # Look for patterns like: "Q.19 In a thin walled..."
        patterns_in_line = [
            r'Q\.\s*(\d+)\s+[A-Z]',
            r'Q\s*(\d+)\s+[A-Z]',
            r'Question\s*(\d+)\s+[A-Z]',
            r'^\s*(\d+)\.\s+[A-Z]',  # "19. In a thin..."
        ]
        
        for pattern in patterns_in_line:
            q_match = re.search(pattern, line)
            if q_match and q_match.group(1).isdigit():
                q_num = f"Q{q_match.group(1)}"
                if q_num not in question_numbers:
                    question_numbers.append(q_num)
                    print(f"    Found in line {i}: '{pattern}': {q_num}")  # Debug
    
    return question_numbers

def get_question_number_for_page(page):
    """Get the most relevant question number for the entire page - NO FALLBACK TO PAGE NUMBER."""
    question_numbers = extract_question_numbers_from_page(page)
    
    if question_numbers:
        # Return the first (lowest) question number on the page
        selected_q = sorted(question_numbers, key=lambda x: int(x[1:]) if x[1:].isdigit() else 999)[0]
        print(f"    Selected question number: {selected_q}")
        return selected_q
    
    # If no question numbers found in text, try OCR on the entire page as HIGH RES
    print("    No question numbers found in text, trying OCR...")
    try:
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        img_array = np.array(img)
        
        # Convert to PIL for OCR
        pil_img = Image.fromarray(img_array)
        
        # Use multiple OCR configurations for better results
        ocr_configs = [
            '--psm 6',  # Uniform block of text
            '--psm 4',  # Single column of text
            '--psm 3',  # Fully automatic page segmentation
        ]
        
        for config in ocr_configs:
            ocr_text = pytesseract.image_to_string(pil_img, config=config)
            print(f"    OCR text with {config}: {ocr_text[:100]}...")
            
            # Search for question numbers in OCR text
            patterns = [
                r'Q\.\s*(\d+)', 
                r'Q\s*(\d+)', 
                r'Question\s*(\d+)',
                r'^\s*(\d+)\.',
                r'\b(\d+)\.\s+[A-Z]'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, ocr_text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    if match.isdigit():
                        q_num = f"Q{match}"
                        print(f"    Found via OCR: {q_num}")
                        return q_num
                        
    except Exception as e:
        print(f"    OCR failed: {e}")
    
    # LAST RESORT: Use sequential numbering but NOT page numbers
    # This will create Q1, Q2, Q3 etc. instead of P1, P2, P3
    print("    Using sequential numbering as last resort")
    return f"Q{page.number + 1}"

def is_likely_diagram(contour, img_width, img_height):
    """Better heuristic to identify actual diagrams vs text blocks."""
    x, y, w, h = cv2.boundingRect(contour)
    area = w * h
    
    # Skip if too small
    if area < min_area or w < 50 or h < 50:
        return False
    
    # Skip very wide or very tall thin regions (likely text lines)
    aspect_ratio = w / h if h > 0 else 0
    if aspect_ratio > 12 or aspect_ratio < 0.08:
        return False
    
    # Skip very small regions that are likely text
    if area < 5000 and (w < 80 or h < 80):
        return False
    
    return True

def get_content_width(img_array):
    """Detect content width by analyzing horizontal pixel density."""
    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
    
    # Calculate horizontal projection (sum of non-white pixels per column)
    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
    horizontal_projection = np.sum(thresh, axis=0)
    
    # Find left and right boundaries where content starts
    threshold = np.max(horizontal_projection) * 0.05  # 5% of max density
    
    left_bound = 0
    for i in range(len(horizontal_projection)):
        if horizontal_projection[i] > threshold:
            left_bound = max(0, i - 10)  # Small buffer
            break
    
    right_bound = len(horizontal_projection) - 1
    for i in range(len(horizontal_projection)-1, -1, -1):
        if horizontal_projection[i] > threshold:
            right_bound = min(len(horizontal_projection)-1, i + 10)  # Small buffer
            break
    
    return left_bound, right_bound

def extract_from_pdf(pdf_path):
    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
    pdf_out_dir = os.path.join(output_folder, pdf_name)
    os.makedirs(pdf_out_dir, exist_ok=True)

    doc = fitz.open(pdf_path)
    total_saved = 0
    print(f"\nüìò Processing {pdf_name} ({len(doc)} pages)...")

    for pno in range(len(doc)):
        page = doc[pno]
        
        # Get question number for this page - FORCE QUESTION NUMBER FORMAT
        page_qnum = get_question_number_for_page(page)
        print(f"  Page {pno+1}: Final question number: {page_qnum}")

        # Process page for images
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        img_array = np.array(img)[:, :, ::-1].copy()

        # Get content width (excluding margins)
        left_bound, right_bound = get_content_width(img_array)
        content_width = right_bound - left_bound
        print(f"    Content area: {left_bound} to {right_bound} (width: {content_width}px)")

        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        th = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 9)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        boxes = []

        for cnt in contours:
            if not is_likely_diagram(cnt, pix.width, pix.height):
                continue
                
            x, y, w, h = cv2.boundingRect(cnt)
            
            # UPDATED: Use content width (excluding margins) instead of full page width
            pad_h = int(0.1 * h + base_pad)
            x0 = left_bound  # Start from content left boundary
            y0 = max(0, y - pad_h)
            x1 = right_bound  # End at content right boundary
            y1 = min(pix.height, y + h + pad_h)
            boxes.append((x0, y0, x1, y1))

        # Sort boxes top-to-bottom
        boxes = sorted(boxes, key=lambda b: (b[1], b[0]))

        for idx, (x0, y0, x1, y1) in enumerate(boxes, start=1):
            crop = img_array[y0:y1, x0:x1]
            
            # Convert to PIL for OCR
            crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
            
            # Detect options in the image
            ocr_text = pytesseract.image_to_string(crop_pil, config='--psm 6').upper()
            option = ""
            for opt in ["A", "B", "C", "D"]:
                if f"({opt})" in ocr_text or f"{opt}." in ocr_text:
                    option = opt
                    break
            
            opt_label = f"_{option}" if option else ""
            
            # Create filename - USE THE DETECTED QUESTION NUMBER
            img_name = f"{pdf_name}_{page_qnum}{opt_label}_img{idx:02d}.png"
            safe_img_name = "".join(c for c in img_name if c.isalnum() or c in "._-")
            
            cv2.imwrite(os.path.join(pdf_out_dir, safe_img_name), crop)
            total_saved += 1
            
            print(f"    Saved: {safe_img_name}")

        print(f"  Page {pno+1}: saved {len(boxes)} diagrams")

    doc.close()
    print(f"‚úÖ Finished {pdf_name}: total {total_saved} diagrams saved.\n")

# === MAIN LOOP ===
pdf_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(".pdf")]
pdf_files.sort()

if not pdf_files:
    print("‚ùå No PDF files found in the folder.")
else:
    for pdf in pdf_files:
        extract_from_pdf(pdf)

print("\nüéâ All PDFs processed successfully!")
print(f"Images saved in: {output_folder}")
