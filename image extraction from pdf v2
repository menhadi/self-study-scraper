import fitz           # PyMuPDF
import cv2
import numpy as np
import os
from PIL import Image
import pytesseract
from pytesseract import Output
import re

# Set this if Tesseract is not in PATH (for Windows)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# === SETTINGS ===
input_folder = r"C:\Users\menha\Downloads\test12"
output_folder = os.path.join(input_folder, "extracted_diagrams_fixed")
os.makedirs(output_folder, exist_ok=True)

zoom = 3.5
base_pad = 15
min_area = 3000

# === SCANNED PDF DETECTION ===
def is_scanned_pdf(pdf_path):
    """Check if PDF is scanned (image-based) rather than text-based."""
    try:
        doc = fitz.open(pdf_path)
        text_count = 0
        image_count = 0
        
        # Check first few pages to determine PDF type
        for pno in range(min(3, len(doc))):
            page = doc[pno]
            
            # Count text blocks
            text_blocks = page.get_text("text")
            if text_blocks.strip():
                text_count += 1
            
            # Count images
            image_list = page.get_images()
            if image_list:
                image_count += 1
        
        doc.close()
        
        # If mostly images and little text, consider it scanned
        is_scanned = image_count > 0 and text_count == 0
        print(f"    PDF Type Detection: text_pages={text_count}, image_pages={image_count}, scanned={is_scanned}")
        return is_scanned
        
    except Exception as e:
        print(f"    Error detecting PDF type: {e}")
        return False  # Default to process if detection fails

# === IMPROVED QUESTION NUMBER EXTRACTION ===
def extract_question_numbers_from_page(page):
    """Extract ALL question numbers from the page text with AGGRESSIVE patterns."""
    text = page.get_text()
    question_numbers = []
    
    print(f"    Raw text preview: {text[:200]}...")  # Debug
    
    # MORE AGGRESSIVE patterns for GATE exam format
    patterns = [
        # Most common: Q.19, Q.20, etc.
        r'Q\.\s*(\d+)',
        # Q19, Q20 (without dot)
        r'Q\s*(\d+)',
        # Question 19, Question 20
        r'Question\s*(\d+)',
        # Q.19) or Q.19.
        r'Q\.\s*(\d+)\)',
        r'Q\.\s*(\d+)\.',
        # In parentheses (Q.19) or (19)
        r'\(\s*Q\.\s*(\d+)\s*\)',
        r'\(\s*(\d+)\s*\)',
        # At start of line: 19. 
        r'^\s*(\d+)\.',
        # Q-19, Q - 19
        r'Q\s*-\s*(\d+)',
        # Q.19: or Q.19-
        r'Q\.\s*(\d+)\:',
        r'Q\.\s*(\d+)\-',
        # Common in questions: "19." at line start
        r'\n\s*(\d+)\.',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            if match.isdigit():
                q_num = f"Q{match}"
                if q_num not in question_numbers:
                    question_numbers.append(q_num)
                    print(f"    Found pattern '{pattern}': {q_num}")  # Debug
    
    # Also try to extract from the raw text lines - MORE AGGRESSIVE
    lines = text.split('\n')
    for i, line in enumerate(lines):
        line = line.strip()
        # Look for patterns like: "Q.19 In a thin walled..."
        patterns_in_line = [
            r'Q\.\s*(\d+)\s+[A-Z]',
            r'Q\s*(\d+)\s+[A-Z]',
            r'Question\s*(\d+)\s+[A-Z]',
            r'^\s*(\d+)\.\s+[A-Z]',  # "19. In a thin..."
        ]
        
        for pattern in patterns_in_line:
            q_match = re.search(pattern, line)
            if q_match and q_match.group(1).isdigit():
                q_num = f"Q{q_match.group(1)}"
                if q_num not in question_numbers:
                    question_numbers.append(q_num)
                    print(f"    Found in line {i}: '{pattern}': {q_num}")  # Debug
    
    return question_numbers

def get_question_number_for_page(page):
    """Get the most relevant question number for the entire page - NO FALLBACK TO PAGE NUMBER."""
    question_numbers = extract_question_numbers_from_page(page)
    
    if question_numbers:
        # Return the first (lowest) question number on the page
        selected_q = sorted(question_numbers, key=lambda x: int(x[1:]) if x[1:].isdigit() else 999)[0]
        print(f"    Selected question number: {selected_q}")
        return selected_q
    
    # If no question numbers found in text, try OCR on the entire page as HIGH RES
    print("    No question numbers found in text, trying OCR...")
    try:
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        img_array = np.array(img)
        
        # Convert to PIL for OCR
        pil_img = Image.fromarray(img_array)
        
        # Use multiple OCR configurations for better results
        ocr_configs = [
            '--psm 6',  # Uniform block of text
            '--psm 4',  # Single column of text
            '--psm 3',  # Fully automatic page segmentation
        ]
        
        for config in ocr_configs:
            ocr_text = pytesseract.image_to_string(pil_img, config=config)
            print(f"    OCR text with {config}: {ocr_text[:100]}...")
            
            # Search for question numbers in OCR text
            patterns = [
                r'Q\.\s*(\d+)', 
                r'Q\s*(\d+)', 
                r'Question\s*(\d+)',
                r'^\s*(\d+)\.',
                r'\b(\d+)\.\s+[A-Z]'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, ocr_text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    if match.isdigit():
                        q_num = f"Q{match}"
                        print(f"    Found via OCR: {q_num}")
                        return q_num
                        
    except Exception as e:
        print(f"    OCR failed: {e}")
    
    # LAST RESORT: Use sequential numbering but NOT page numbers
    # This will create Q1, Q2, Q3 etc. instead of P1, P2, P3
    print("    Using sequential numbering as last resort")
    return f"Q{page.number + 1}"

def is_likely_diagram(contour, img_width, img_height):
    """Better heuristic to identify actual diagrams vs text blocks."""
    x, y, w, h = cv2.boundingRect(contour)
    area = w * h
    
    # Skip if too small
    if area < min_area or w < 50 or h < 50:
        return False
    
    # Skip very wide or very tall thin regions (likely text lines)
    aspect_ratio = w / h if h > 0 else 0
    if aspect_ratio > 12 or aspect_ratio < 0.08:
        return False
    
    # Skip very small regions that are likely text
    if area < 5000 and (w < 80 or h < 80):
        return False
    
    return True

def get_content_width(img_array):
    """Detect content width by analyzing horizontal pixel density - IMPROVED for full text width."""
    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
    
    # Calculate horizontal projection (sum of non-white pixels per column)
    _, thresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY_INV)
    
    # Apply morphological operations to remove noise
    kernel = np.ones((3, 3), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
    
    horizontal_projection = np.sum(thresh, axis=0)
    
    # Find left and right boundaries where content starts
    threshold = np.max(horizontal_projection) * 0.02
    
    # Find left boundary
    left_bound = 0
    for i in range(len(horizontal_projection)):
        if horizontal_projection[i] > threshold:
            left_bound = max(0, i - 10)  # Reduced padding
            break
    
    # Find right boundary  
    right_bound = len(horizontal_projection) - 1
    for i in range(len(horizontal_projection)-1, -1, -1):
        if horizontal_projection[i] > threshold:
            right_bound = min(len(horizontal_projection)-1, i + 10)  # Reduced padding
            break
    
    # Additional check: Ensure we capture the full text region width
    # Look for continuous content regions
    content_threshold = np.max(horizontal_projection) * 0.1
    content_regions = horizontal_projection > content_threshold
    
    # Find the leftmost and rightmost content regions
    if np.any(content_regions):
        content_indices = np.where(content_regions)[0]
        if len(content_indices) > 0:
            detected_left = max(0, content_indices[0] - 15)
            detected_right = min(len(horizontal_projection)-1, content_indices[-1] + 15)
            
            # Use the wider of the two detections
            if (detected_right - detected_left) > (right_bound - left_bound):
                left_bound = detected_left
                right_bound = detected_right
    
    # Final safety check - ensure reasonable width
    min_content_width = len(horizontal_projection) * 0.7  # Increased to 70%
    current_width = right_bound - left_bound
    
    if current_width < min_content_width:
        # Expand to capture more content
        expansion = (min_content_width - current_width) / 2
        left_bound = max(0, int(left_bound - expansion))
        right_bound = min(len(horizontal_projection)-1, int(right_bound + expansion))
    
    print(f"    Content bounds: {left_bound} to {right_bound} (width: {right_bound - left_bound}px)")
    return left_bound, right_bound

def extract_from_pdf(pdf_path, relative_path=""):
    # Check if file exists
    if not os.path.exists(pdf_path):
        print(f"‚ùå File not found: {pdf_path}")
        return
        
    # Check if PDF is scanned - only process scanned PDFs
    if not is_scanned_pdf(pdf_path):
        print(f"‚è≠Ô∏è  Skipping non-scanned PDF: {pdf_path}")
        return
        
    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
    
    # Create output directory structure that mirrors input structure
    if relative_path:
        pdf_out_dir = os.path.join(output_folder, relative_path, pdf_name)
    else:
        pdf_out_dir = os.path.join(output_folder, pdf_name)
        
    os.makedirs(pdf_out_dir, exist_ok=True)

    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        print(f"‚ùå Error opening PDF {pdf_path}: {e}")
        return

    total_saved = 0
    print(f"\nüìò Processing SCANNED PDF {pdf_path} ({len(doc)} pages)...")

    for pno in range(len(doc)):
        page = doc[pno]
        
        # Get question number for this page - FORCE QUESTION NUMBER FORMAT
        page_qnum = get_question_number_for_page(page)
        print(f"  Page {pno+1}: Final question number: {page_qnum}")

        # Process page for images
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        img_array = np.array(img)[:, :, ::-1].copy()

        # Get content width (excluding margins) - FULL TEXT WIDTH
        left_bound, right_bound = get_content_width(img_array)

        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        th = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 9)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        boxes = []

        for cnt in contours:
            if not is_likely_diagram(cnt, pix.width, pix.height):
                continue
                
            x, y, w, h = cv2.boundingRect(cnt)
            
            # UPDATED: Use full content width (left_bound to right_bound)
            pad_h = int(0.14 * h + base_pad)
            x0 = left_bound  # Start from content left boundary
            y0 = max(0, y - pad_h)
            x1 = right_bound  # End at content right boundary (FULL WIDTH)
            y1 = min(pix.height, y + h + pad_h)
            boxes.append((x0, y0, x1, y1))

        # Sort boxes top-to-bottom
        boxes = sorted(boxes, key=lambda b: (b[1], b[0]))

        # Remove duplicates and very small boxes
        boxes = [box for box in boxes if (box[2]-box[0]) * (box[3]-box[1]) > 5000]

        for idx, (x0, y0, x1, y1) in enumerate(boxes, start=1):
            crop = img_array[y0:y1, x0:x1]
            
            # Skip if it's mostly white space
            gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
            if np.mean(gray_crop) > 240:  # Mostly white
                continue
            
            # Convert to PIL for OCR
            crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
            
            # Detect options in the image
            ocr_text = pytesseract.image_to_string(crop_pil, config='--psm 6').upper()
            option = ""
            for opt in ["A", "B", "C", "D"]:
                if f"({opt})" in ocr_text or f"{opt}." in ocr_text:
                    option = opt
                    break
            
            opt_label = f"_{option}" if option else ""
            
            # Create filename - USE THE DETECTED QUESTION NUMBER
            img_name = f"{pdf_name}_{page_qnum}{opt_label}_img{idx:02d}.png"
            safe_img_name = "".join(c for c in img_name if c.isalnum() or c in "._-")
            
            cv2.imwrite(os.path.join(pdf_out_dir, safe_img_name), crop)
            total_saved += 1
            
            print(f"    Saved: {safe_img_name}")

        print(f"  Page {pno+1}: saved {len(boxes)} diagrams")

    doc.close()
    print(f"‚úÖ Finished {pdf_path}: total {total_saved} diagrams saved.\n")

def find_pdf_files(root_folder):
    """Find all PDF files recursively in all subfolders."""
    pdf_files = []
    for root, dirs, files in os.walk(root_folder):
        # Skip the output folder to avoid processing extracted images
        if "extracted_diagrams_fixed" in root:
            continue
            
        for file in files:
            if file.lower().endswith('.pdf'):
                full_path = os.path.join(root, file)
                # Calculate relative path for output directory structure
                relative_path = os.path.relpath(root, root_folder)
                if relative_path == '.':
                    relative_path = ""
                pdf_files.append((full_path, relative_path))
                print(f"üìÑ Found PDF: {full_path}")
    return pdf_files

# === MAIN LOOP ===
print(f"üîç Searching for PDF files in: {input_folder}")
print(f"üìÅ Output folder: {output_folder}")

# Find all PDF files recursively in all subfolders
pdf_files_with_paths = find_pdf_files(input_folder)
pdf_files_with_paths.sort(key=lambda x: x[0])  # Sort by file path

if not pdf_files_with_paths:
    print("‚ùå No PDF files found in the folder or subfolders.")
    print("üí° Check that:")
    print("   - The input folder path is correct")
    print("   - PDF files exist in the folder or subfolders")
    print("   - File extensions are .pdf (case insensitive)")
else:
    print(f"üéØ Found {len(pdf_files_with_paths)} PDF files to process:")
    for pdf_path, relative_path in pdf_files_with_paths:
        print(f"   - {pdf_path}")
    
    print("\nüöÄ Starting extraction (SCANNED PDFs ONLY)...")
    for pdf_path, relative_path in pdf_files_with_paths:
        extract_from_pdf(pdf_path, relative_path)

print("\nüéâ All SCANNED PDFs processed successfully!")
print(f"üìÇ Images saved in: {output_folder}")
