import requests
import base64
import json
import re
from PIL import Image
from io import BytesIO
from google.oauth2 import service_account
from googleapiclient.discovery import build
from typing import Dict, List, Tuple
import time
import concurrent.futures

class MultiQuestionExtractor:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
    
    def optimize_image(self, image_url, target_width=768):
        """Optimize image for better text readability"""
        try:
            response = requests.get(image_url, timeout=30)
            img = Image.open(BytesIO(response.content))
            
            width, height = img.size
            if width > target_width:
                ratio = target_width / float(width)
                new_height = int(float(height) * ratio)
                img = img.resize((target_width, new_height), Image.Resampling.LANCZOS)
            
            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')
                
            output = BytesIO()
            img.save(output, format='JPEG', quality=90, optimize=True)
            return base64.b64encode(output.getvalue()).decode('utf-8')
            
        except Exception as e:
            print(f"Image optimization failed: {e}")
            return None
    
    def extract_all_questions_from_image(self, image_url: str, file_name: str) -> List[Dict]:
        """Extract ALL questions from a single image containing multiple questions"""
        
        base64_image = self.optimize_image(image_url)
        if not base64_image:
            return [{"error": "Image processing failed", "file_name": file_name}]
        
        prompt = """ANALYZE THIS EDUCATIONAL QUESTION PAPER IMAGE:

EXTRACTION RULES:
1. Extract EACH question separately
2. IGNORE headers, footers, page numbers, instructions like "Q.1 - Q.20 carry one mark each"
3. Extract ONLY the actual questions and their options
4. For MATHEMATICAL EQUATIONS and CHEMICAL FORMULAS, convert to UNICODE TEXT format (NOT LaTeX)
5. DETECT if there are any DIAGRAMS, IMAGES, or VISUAL ELEMENTS in:
   - The question itself
   - Any of the options (A, B, C, D)
6. For each question, extract:
   - Full question text
   - All options (A, B, C, D)
   - Question number
   - Whether question contains image/diagram (true/false)
   - Which options contain images/diagrams (list of option letters)

IMAGE DETECTION EXAMPLES:
- If question has a circuit diagram: "has_question_image": true
- If option B has a graph: "options_with_images": ["B"]
- If multiple options have images: "options_with_images": ["A", "C"]
- If no images: "has_question_image": false, "options_with_images": []

MATHEMATICAL CONVERSION EXAMPLES:
- LaTeX: \( f(\theta) = \begin{bmatrix} \cos\theta & \sin\theta \\ -\sin\theta & \cos\theta \end{bmatrix} \)
- Unicode: f(Î¸) = [[cos Î¸, sin Î¸], [-sin Î¸, cos Î¸]]

OUTPUT FORMAT: Return ONLY valid JSON array:
[
  {
    "question_number": "Q.1",
    "question_text": "full question text with Unicode math/chemistry",
    "option_a": "option A text with Unicode",
    "option_b": "option B text with Unicode", 
    "option_c": "option C text with Unicode",
    "option_d": "option D text with Unicode",
    "has_question_image": true/false,
    "options_with_images": ["A", "C"] // or empty array
  }
]

EXCLUDE: Page headers, footers, instructions, "carry one mark each", page numbers
USE UNICODE: For all mathematical symbols and chemical formulas"""
        
        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 4000,
            "temperature": 0.1
        }
        
        try:
            print(f"Extracting questions from: {file_name}")
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                print("Raw extraction completed")
                
                questions = self._parse_questions_json(content)
                
                # Add file name to each question and ensure image fields exist
                for question in questions:
                    question["file_name"] = file_name
                    # Ensure image detection fields exist
                    if "has_question_image" not in question:
                        question["has_question_image"] = False
                    if "options_with_images" not in question:
                        question["options_with_images"] = []
                
                print(f"âœ… Extracted {len(questions)} questions from {file_name}")
                return questions
            else:
                return [{"error": f"API Error: {response.status_code}", "file_name": file_name}]
                
        except Exception as e:
            return [{"error": f"Extraction failed: {str(e)}", "file_name": file_name}]
    
    def process_image_batch(self, image_batch: List[Tuple[str, str]]) -> List[Dict]:
        """Process a batch of images concurrently"""
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # Submit all tasks
            future_to_image = {
                executor.submit(self.extract_all_questions_from_image, url, name): (name, url) 
                for name, url in image_batch
            }
            
            # Collect results as they complete
            for future in concurrent.futures.as_completed(future_to_image):
                name, url = future_to_image[future]
                try:
                    questions = future.result()
                    results.extend(questions)
                    print(f"âœ… Completed batch item: {name}")
                except Exception as e:
                    error_result = [{"error": f"Batch processing failed: {str(e)}", "file_name": name}]
                    results.extend(error_result)
                    print(f"âŒ Failed batch item: {name}")
        
        return results
    
    def get_correct_answers_batch(self, questions: List[Dict]) -> List[Dict]:
        """Get correct answers for a batch of questions"""
        results = []
        
        # Process questions in smaller batches to avoid rate limits
        batch_size = 5
        for i in range(0, len(questions), batch_size):
            batch = questions[i:i + batch_size]
            print(f"ðŸ”„ Analyzing answer batch {i//batch_size + 1}/{(len(questions)-1)//batch_size + 1}")
            
            for question in batch:
                if "error" in question:
                    results.append(question)
                    continue
                
                answer_result = self._analyze_single_question(question)
                # Combine question data with answer
                combined = {**question, **answer_result}
                results.append(combined)
                
                # Smaller delay for batch processing
                time.sleep(1)
        
        return results
    
    def _analyze_single_question(self, question: Dict) -> Dict:
        """Analyze a single question for correct answer"""
        
        # Include image information in the prompt for context
        image_info = ""
        if question.get("has_question_image"):
            image_info = " [Note: Question contains diagram/image]"
        if question.get("options_with_images"):
            image_info += f" [Options with images: {', '.join(question['options_with_images'])}]"
        
        prompt = f"""Question: {question.get('question_text', '')}{image_info}
Options:
A: {question.get('option_a', '')}
B: {question.get('option_b', '')} 
C: {question.get('option_c', '')}
D: {question.get('option_d', '')}

Determine the correct option and provide brief explanation.
Return ONLY JSON:
{{
    "correct_answer": "A/B/C/D",
    "explanation": "brief explanation"
}}"""
        
        payload = {
            "model": "gpt-4o",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 300,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                return self._parse_json_response(content)
            else:
                return {"correct_answer": "Error", "explanation": f"API: {response.status_code}"}
        except Exception as e:
            return {"correct_answer": "Error", "explanation": f"Analysis failed: {str(e)}"}
    
    def _parse_questions_json(self, text: str) -> List[Dict]:
        """Parse the questions JSON array"""
        try:
            # Clean the text
            clean_text = re.sub(r'```json|```', '', text).strip()
            questions = json.loads(clean_text)
            
            # Validate it's a list
            if isinstance(questions, list):
                return questions
            else:
                return [questions]  # Wrap single question in list
                
        except json.JSONDecodeError as e:
            print(f"JSON parsing failed: {e}")
            return self._manual_question_extraction(text)
    
    def _manual_question_extraction(self, text: str) -> List[Dict]:
        """Fallback manual extraction"""
        print("Using fallback manual extraction")
        questions = []
        lines = text.split('\n')
        
        current_question = None
        current_option = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Detect question number
            q_match = re.match(r'^(Q\.\s*\d+|[Qq]uestion\s*\d+)', line)
            if q_match:
                # Save previous question if exists
                if current_question and current_question.get('question_text'):
                    questions.append(current_question)
                
                # Start new question
                current_question = {
                    "question_number": q_match.group(0),
                    "question_text": line[len(q_match.group(0)):].strip(),
                    "option_a": "", "option_b": "", "option_c": "", "option_d": "",
                    "has_question_image": False,
                    "options_with_images": []
                }
                current_option = None
                continue
            
            # Detect options
            option_match = re.match(r'^\(([A-D])\)\s*(.+)', line)
            if not option_match:
                option_match = re.match(r'^([A-D])\.\s*(.+)', line)
            if not option_match:
                option_match = re.match(r'^([A-D])\s*(.+)', line)
            
            if option_match and current_question:
                option_key = f"option_{option_match.group(1).lower()}"
                current_question[option_key] = option_match.group(2).strip()
                current_option = option_key
            elif current_option and current_question:
                # Continue current option
                current_question[current_option] += " " + line
            elif current_question and not any(current_question[opt] for opt in ['option_a', 'option_b', 'option_c', 'option_d']):
                # This is still question text
                current_question["question_text"] += " " + line
        
        # Add the last question
        if current_question and current_question.get('question_text'):
            questions.append(current_question)
        
        return questions
    
    def _parse_json_response(self, text: str) -> Dict:
        """Parse single JSON response"""
        try:
            clean_text = re.sub(r'```json|```', '', text).strip()
            return json.loads(clean_text)
        except:
            return {"correct_answer": "", "explanation": text}

class GoogleSheetProcessor:
    def __init__(self, credentials_file: str, sheet_id: str, api_key: str, sheet_tab: str = "Sheet4"):
        self.sheet_id = sheet_id
        self.sheet_tab = sheet_tab
        self.extractor = MultiQuestionExtractor(api_key)
        self.service = self._authenticate_google_sheets(credentials_file)
    
    def _authenticate_google_sheets(self, credentials_file: str):
        """Authenticate with Google Sheets API"""
        try:
            SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
            creds = service_account.Credentials.from_service_account_file(
                credentials_file, scopes=SCOPES)
            
            return build('sheets', 'v4', credentials=creds)
        except Exception as e:
            print(f"Google Sheets authentication failed: {e}")
            raise
    
    def read_sheet_data(self, sheet_range: str = None) -> List[List]:
        """Read image URLs and file names from Google Sheets"""
        if sheet_range is None:
            sheet_range = f"{self.sheet_tab}!A:B"
            
        try:
            sheet = self.service.spreadsheets()
            result = sheet.values().get(
                spreadsheetId=self.sheet_id,
                range=sheet_range
            ).execute()
            
            values = result.get('values', [])
            print(f"Read {len(values)} rows from sheet")
            return values
        except Exception as e:
            print(f"Error reading sheet data: {e}")
            return []
    
    def update_sheet(self, updates: List[List], range: str):
        """Update Google Sheets with results"""
        try:
            body = {'values': updates}
            sheet = self.service.spreadsheets()
            result = sheet.values().update(
                spreadsheetId=self.sheet_id,
                range=range,
                valueInputOption='RAW',
                body=body
            ).execute()
            
            print(f"Updated {len(updates)} rows in range {range}")
            return result
        except Exception as e:
            print(f"Error updating sheet: {e}")
            raise
    
    def clear_previous_data(self, range: str):
        """Clear previous data from specified range"""
        try:
            sheet = self.service.spreadsheets()
            result = sheet.values().clear(
                spreadsheetId=self.sheet_id,
                range=range
            ).execute()
            print(f"Cleared previous data from {range}")
            return result
        except Exception as e:
            print(f"Error clearing data: {e}")
    
    def process_all_images(self, batch_size: int = 3):
        """Process all images in batches and extract multiple questions from each"""
        data = self.read_sheet_data(f"{self.sheet_tab}!A:B")
        
        if not data or len(data) < 2:
            print("No data found or insufficient columns")
            return
        
        all_questions = []
        total_images = 0
        
        # Clear previous results (columns C through N)
        self.clear_previous_data(f"{self.sheet_tab}!C:N")
        
        # Prepare image batches
        image_batches = []
        current_batch = []
        
        for i, row in enumerate(data[1:], start=2):
            while len(row) < 2:
                row.append("")
            
            file_name = row[0] if len(row) > 0 else f"Image_{i}"
            image_url = row[1]
            
            if not image_url or not image_url.startswith('http'):
                print(f"Skipping row {i}: No valid URL")
                continue
            
            current_batch.append((file_name, image_url))
            
            # When batch is full, process it
            if len(current_batch) >= batch_size:
                image_batches.append(current_batch)
                current_batch = []
        
        # Add remaining images as last batch
        if current_batch:
            image_batches.append(current_batch)
        
        print(f"\nðŸ“¦ Processing {len(image_batches)} batches with {batch_size} images each")
        
        # Process each batch
        for batch_num, image_batch in enumerate(image_batches, 1):
            print(f"\n{'='*70}")
            print(f"ðŸ”„ PROCESSING BATCH {batch_num}/{len(image_batches)}")
            print(f"{'='*70}")
            
            # Process batch concurrently
            batch_questions = self.extractor.process_image_batch(image_batch)
            
            # Filter out errors and get correct answers
            valid_questions = [q for q in batch_questions if "error" not in q]
            if valid_questions:
                print(f"ðŸ”„ Getting correct answers for {len(valid_questions)} questions...")
                complete_questions = self.extractor.get_correct_answers_batch(valid_questions)
                all_questions.extend(complete_questions)
                total_images += len(image_batch)
            
            # Add error questions as well
            error_questions = [q for q in batch_questions if "error" in q]
            all_questions.extend(error_questions)
            
            print(f"âœ… Batch {batch_num} completed: {len(valid_questions)} questions extracted")
            
            # Rate limiting between batches
            if batch_num < len(image_batches):
                print("â³ Waiting before next batch...")
                time.sleep(5)
        
        # Prepare updates for Google Sheets
        updates = []
        for question in all_questions:
            if "error" in question:
                updates.append([
                    question.get("file_name", ""),         # Column C: File Name
                    question.get("source_row", ""),        # Column D: Source Row
                    f"Error: {question['error']}",         # Column E: Error
                    "", "", "", "", "", "", "", "", ""     # Empty columns for consistency
                ])
            else:
                # Format image information
                has_question_image = "Yes" if question.get("has_question_image") else "No"
                options_with_images = ", ".join(question.get("options_with_images", [])) or "None"
                
                updates.append([
                    question.get("file_name", ""),         # Column C: File Name
                    question.get("source_row", ""),        # Column D: Source Row  
                    question.get("question_number", ""),   # Column E: Question Number
                    question.get("question_text", ""),     # Column F: Question Text
                    question.get("option_a", ""),          # Column G: Option A
                    question.get("option_b", ""),          # Column H: Option B
                    question.get("option_c", ""),          # Column I: Option C
                    question.get("option_d", ""),          # Column J: Option D
                    has_question_image,                    # Column K: Question Has Image
                    options_with_images,                   # Column L: Options With Images
                    question.get("correct_answer", ""),    # Column M: Correct Answer
                    question.get("explanation", "")        # Column N: Explanation
                ])
        
        # Write all questions to sheet
        if updates:
            # Write header row
            header = [
                "File Name", "Source Row", "Q Number", "Question Text", 
                "Option A", "Option B", "Option C", "Option D", 
                "Question Has Image", "Options With Images",
                "Correct Answer", "Explanation"
            ]
            updates.insert(0, header)
            
            update_range = f"{self.sheet_tab}!C2:N{len(updates)+1}"
            self.update_sheet(updates, update_range)
            
            print(f"\nðŸŽ‰ PROCESSING COMPLETED!")
            print(f"ðŸ“Š Total Images Processed: {total_images}")
            print(f"ðŸ“ Total Questions Extracted: {len([q for q in all_questions if 'error' not in q])}")
            print(f"ðŸ’¾ Results saved to columns C-N")
            print(f"ðŸ“‹ Column Structure:")
            print(f"   C: File Name")
            print(f"   D: Source Row") 
            print(f"   E: Question Number")
            print(f"   F: Question Text (Unicode Math/Chemistry)")
            print(f"   G: Option A (Unicode)")
            print(f"   H: Option B (Unicode)")
            print(f"   I: Option C (Unicode)")
            print(f"   J: Option D (Unicode)")
            print(f"   K: Question Has Image (Yes/No)")
            print(f"   L: Options With Images (A,B,C or None)")
            print(f"   M: Correct Answer")
            print(f"   N: Explanation")
        else:
            print("âŒ No questions were extracted")

def main():
    # Configuration
    OPENAI_API_KEY = "your_openai_api_key_here"
    
    if not OPENAI_API_KEY or OPENAI_API_KEY == "your_openai_api_key_here":
        print("âŒ Please set your OpenAI API key")
        return
    
    SHEET_TAB = "Sheet4"
    GOOGLE_SHEET_ID = "1U6gW0yqh3GZlkyxvhF_5k3sXMP8GwZT-TNsXqKv7S1o"
    CREDENTIALS_FILE = "service-account.json"
    
    # ðŸŽ¯ CONFIGURATION: Change batch size here
    BATCH_SIZE = 3  # Process 3 images at a time
    
    try:
        print("\n" + "="*80)
        print("ADVANCED MULTI-QUESTION EXTRACTION WITH BATCH PROCESSING")
        print(f"Batch Size: {BATCH_SIZE} images per batch")
        print("Features:")
        print("âœ“ Batch processing for faster execution")
        print("âœ“ Detects images in questions and options")
        print("âœ“ Converts math equations to Unicode")
        print("âœ“ Includes file name in each row")
        print("="*80)
        
        processor = GoogleSheetProcessor(CREDENTIALS_FILE, GOOGLE_SHEET_ID, OPENAI_API_KEY, SHEET_TAB)
        processor.process_all_images(batch_size=BATCH_SIZE)
    except Exception as e:
        print(f"âŒ Processing failed: {e}")

if __name__ == "__main__":
    main()
