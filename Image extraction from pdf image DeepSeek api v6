import cv2
import numpy as np
import os
import csv
import re
import requests
import base64
import json
from collections import defaultdict
import traceback
import shutil
from datetime import datetime

# ======================================
# ‚úÖ CONFIGURATION
# ======================================
INPUT_ROOT  = r"D:\Vector Academy\Contents\PYQ\GATE\Image"
OUTPUT_ROOT = r"D:\Vector Academy\Contents\PYQ\GATE\Image1"
CSV_PATH    = r"C:\Users\menha\Downloads\input.csv"
DEBUG_DIR   = r"C:\Users\menha\Downloads\test\debug"

# DeepSeek Vision API Configuration
DEEPSEEK_API_KEY = "your-deepseek-api-key-here"  # Replace with your actual API key
USE_VISION_API = True  # Set to True to enable Vision API, False for traditional method
VISION_API_CONFIDENCE_THRESHOLD = 0.7  # Minimum confidence for Vision API decisions

# Safety Settings
SAFETY_MODE = True
BACKUP_BEFORE_OVERWRITE = True

os.makedirs(OUTPUT_ROOT, exist_ok=True)
os.makedirs(DEBUG_DIR, exist_ok=True)

# Create a backup directory if needed
if BACKUP_BEFORE_OVERWRITE:
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    BACKUP_DIR = os.path.join(OUTPUT_ROOT, f"backup_{timestamp}")
    os.makedirs(BACKUP_DIR, exist_ok=True)
    print(f"üìÇ Backup directory created: {BACKUP_DIR}")

# Performance settings
VISION_API_BATCH_SIZE = 5  # Process multiple crops in one API call for efficiency
CACHE_VISION_RESULTS = True  # Cache API results to avoid redundant calls
vision_cache = {}  # Cache for Vision API results

min_area = 3500

# ======================================
# ‚úÖ VISION API FUNCTIONS
# ======================================
def encode_image_to_base64(image):
    """Encode OpenCV image to base64 string"""
    _, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    return base64.b64encode(buffer).decode('utf-8')

def analyze_crops_with_deepseek(crops, descriptions=None):
    """
    Use DeepSeek Vision API to analyze multiple image crops
    Returns list of classifications: 'image', 'text', or 'unknown'
    """
    if not DEEPSEEK_API_KEY or not USE_VISION_API:
        return ['unknown'] * len(crops)
    
    # Check cache first
    cache_key = tuple(encode_image_to_base64(crop)[:100] for crop in crops)
    if CACHE_VISION_RESULTS and cache_key in vision_cache:
        return vision_cache[cache_key]
    
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
        }
        
        messages = [
            {
                "role": "user",
                "content": []
            }
        ]
        
        # Add system message
        system_msg = {
            "type": "text",
            "text": """Analyze each image and classify it as either:
            1. 'image' - if it contains diagrams, graphs, charts, illustrations, or non-text visuals
            2. 'text' - if it contains primarily text, equations, or formulas
            3. 'unknown' - if you're not sure
            
            Return ONLY a JSON array with one classification per image in the same order.
            Example: ["image", "text", "image"]"""
        }
        messages[0]["content"].append(system_msg)
        
        # Add each image
        for i, crop in enumerate(crops):
            img_base64 = encode_image_to_base64(crop)
            img_msg = {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_base64}"
                }
            }
            messages[0]["content"].append(img_msg)
            
            # Add description if provided
            if descriptions and i < len(descriptions):
                desc_msg = {
                    "type": "text",
                    "text": f"Image {i+1}: {descriptions[i]}"
                }
                messages[0]["content"].append(desc_msg)
        
        payload = {
            "model": "deepseek-chat",  # Use appropriate DeepSeek vision model
            "messages": messages,
            "max_tokens": 500
        }
        
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            
            # Try to parse JSON response
            try:
                classifications = json.loads(answer)
                if CACHE_VISION_RESULTS:
                    vision_cache[cache_key] = classifications
                return classifications
            except json.JSONDecodeError:
                # Fallback: parse text response
                classifications = []
                lines = answer.lower().split('\n')
                for line in lines:
                    if 'image' in line and 'text' not in line:
                        classifications.append('image')
                    elif 'text' in line:
                        classifications.append('text')
                    else:
                        classifications.append('unknown')
                
                # Pad or truncate to match input length
                if len(classifications) < len(crops):
                    classifications.extend(['unknown'] * (len(crops) - len(classifications)))
                elif len(classifications) > len(crops):
                    classifications = classifications[:len(crops)]
                
                if CACHE_VISION_RESULTS:
                    vision_cache[cache_key] = classifications
                return classifications
        else:
            print(f"‚ö†Ô∏è  DeepSeek API Error: {response.status_code} - {response.text}")
            return ['unknown'] * len(crops)
            
    except Exception as e:
        print(f"‚ö†Ô∏è  DeepSeek API call failed: {e}")
        return ['unknown'] * len(crops)

def is_text_like_enhanced(crop, threshold=0.20, use_traditional=True):
    """
    Enhanced image/text classification using multiple methods
    """
    if crop.size == 0:
        return True
    
    # Traditional method (fast, local)
    if use_traditional:
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 60, 160)
        density = np.sum(edges > 0) / edges.size
        
        # If traditional method is very confident, use it
        if density > 0.35:  # Definitely text-like
            return True
        elif density < 0.15:  # Definitely image-like
            return False
        # For ambiguous cases (0.15-0.35), we'll use Vision API if enabled
    
    # Use Vision API for ambiguous cases or if traditional method is disabled
    if USE_VISION_API and DEEPSEEK_API_KEY:
        classification = analyze_crops_with_deepseek([crop])[0]
        return classification == 'text'
    
    # Fallback to traditional method
    return density > threshold if use_traditional else False

def batch_classify_crops(crops, descriptions=None):
    """
    Classify multiple crops in batch using Vision API
    """
    if not USE_VISION_API or not DEEPSEEK_API_KEY or not crops:
        return [False] * len(crops)  # Default to not text-like
    
    # Process in batches for efficiency
    all_classifications = []
    for i in range(0, len(crops), VISION_API_BATCH_SIZE):
        batch = crops[i:i + VISION_API_BATCH_SIZE]
        batch_descriptions = descriptions[i:i + VISION_API_BATCH_SIZE] if descriptions else None
        
        classifications = analyze_crops_with_deepseek(batch, batch_descriptions)
        
        # Convert to boolean (text-like or not)
        for cls in classifications:
            all_classifications.append(cls == 'text')
    
    return all_classifications

# ======================================
# ‚úÖ HELPER FUNCTIONS
# ======================================
def parse_question_number(question_str):
    """Parse question number from string, handling formats like 'Q38', '38', 'Q.38', etc."""
    if not question_str:
        return 999
    
    # Remove any whitespace
    question_str = str(question_str).strip()
    
    # If it's already a number, return it
    try:
        return int(question_str)
    except ValueError:
        pass
    
    # Try to extract numbers from the string
    patterns = [
        r'Q\.?\s*(\d+)',      # Q38, Q.38, Q 38
        r'Question\s*(\d+)',   # Question 38
        r'(\d+)',              # Just digits
    ]
    
    for pattern in patterns:
        match = re.search(pattern, question_str, re.IGNORECASE)
        if match:
            try:
                return int(match.group(1))
            except ValueError:
                continue
    
    # If we can't parse it, try to get the last set of digits
    digits = re.findall(r'\d+', question_str)
    if digits:
        try:
            return int(digits[-1])
        except ValueError:
            pass
    
    return 999

def check_existing_files(save_dir):
    """Check if there are existing files in the output directory"""
    if os.path.exists(save_dir):
        existing_files = os.listdir(save_dir)
        image_files = [f for f in existing_files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
        return len(image_files)
    return 0

def backup_existing_files(source_dir, backup_dir):
    """Backup existing files before processing"""
    if not os.path.exists(source_dir):
        return
    
    # Create corresponding backup subdirectory
    rel_path = os.path.relpath(source_dir, OUTPUT_ROOT)
    target_backup_dir = os.path.join(backup_dir, rel_path)
    os.makedirs(target_backup_dir, exist_ok=True)
    
    # Copy all image files
    for filename in os.listdir(source_dir):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            src = os.path.join(source_dir, filename)
            dst = os.path.join(target_backup_dir, filename)
            shutil.copy2(src, dst)
    
    print(f"   üì¶ Backed up {len(os.listdir(source_dir))} files from {source_dir}")

def safe_save_image(image, filepath):
    """Safely save an image with overwrite protection"""
    if SAFETY_MODE and os.path.exists(filepath):
        # Generate unique filename
        base, ext = os.path.splitext(filepath)
        counter = 1
        while os.path.exists(filepath):
            filepath = f"{base}_{counter}{ext}"
            counter += 1
        print(f"   ‚ö†Ô∏è  File exists, saving as: {os.path.basename(filepath)}")
    
    cv2.imwrite(filepath, image)
    return filepath

def crop_header_footer(img):
    h, w, _ = img.shape
    top = int(0.06 * h)
    bottom = int(0.95 * h)
    return img[top:bottom, :]

def iou(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])
    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])
    inter = max(0, xB - xA) * max(0, yB - yA)
    union = boxA[2]*boxA[3] + boxB[2]*boxB[3] - inter
    return inter / union if union != 0 else 0

def non_max_suppression(boxes, thresh=0.45):
    if not boxes:
        return []
    boxes = sorted(boxes, key=lambda b: b[2]*b[3], reverse=True)
    final = []
    while boxes:
        best = boxes.pop(0)
        final.append(best)
        boxes = [b for b in boxes if iou(best, b) < thresh]
    return final

def pad_box(x, y, w, h, img_w, img_h, pad_ratio=0.10):
    px = int(w * pad_ratio)
    py = int(h * pad_ratio)
    x0 = max(0, x - px)
    y0 = max(0, y - py)
    x1 = min(img_w, x + w + px)
    y1 = min(img_h, y + h + py)
    return x0, y0, x1 - x0, y1 - y0

def visualize_page_detection(page_cropped, boxes, questions, file_name, save_dir):
    """Visualize detected boxes and question positions for debugging"""
    debug_img = page_cropped.copy()
    
    # Draw all detected boxes
    for i, (x, y, w, h) in enumerate(boxes):
        cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
        cv2.putText(debug_img, f"Box {i}", (x, y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    # Draw estimated question positions
    H, W = page_cropped.shape[:2]
    for i, (question_num, _, _) in enumerate(questions):
        estimated_y = int((H / len(questions)) * (i + 0.5))
        cv2.line(debug_img, (0, estimated_y), (W, estimated_y), (255, 0, 0), 2)
        cv2.putText(debug_img, f"Q{question_num}", (10, estimated_y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
    
    # Clean file name for saving
    clean_name = os.path.splitext(file_name)[0].replace(' ', '_').replace('/', '_')
    debug_path = os.path.join(save_dir, f"debug_{clean_name}.png")
    safe_save_image(debug_img, debug_path)
    print(f"   üìä Debug visualization saved: {debug_path}")
    return debug_path

def extract_images_with_vision_assistance(page_cropped, boxes, questions, save_dir, file_name):
    """
    Extract images using Vision API for intelligent matching
    """
    H, W = page_cropped.shape[:2]
    questions_sorted = sorted(questions, key=lambda x: x[0])
    boxes_sorted = sorted(boxes, key=lambda b: b[1])  # Sort by y-coordinate
    
    print(f"   üì¶ Processing {len(boxes_sorted)} boxes for {len(questions_sorted)} questions")
    
    # Extract all crops
    crops = []
    box_info = []
    for i, (x, y, w, h) in enumerate(boxes_sorted):
        crop = page_cropped[y:y + h, x:x + w]
        crops.append(crop)
        box_info.append({
            'index': i,
            'box': (x, y, w, h),
            'area': w * h,
            'center_y': y + h/2
        })
    
    # Use Vision API to classify all crops at once
    print(f"   ü§ñ Using Vision API to classify {len(crops)} crops...")
    is_text_list = batch_classify_crops(crops)
    
    # Separate image boxes from text boxes
    image_boxes = []
    text_boxes = []
    
    for i, (is_text, info) in enumerate(zip(is_text_list, box_info)):
        if not is_text:
            image_boxes.append(info)
            print(f"   üì∑ Box {i}: Classified as IMAGE (size: {info['area']}px)")
        else:
            text_boxes.append(info)
            print(f"   üìù Box {i}: Classified as TEXT (size: {info['area']}px)")
    
    print(f"   üìä Results: {len(image_boxes)} image boxes, {len(text_boxes)} text boxes")
    
    # If we have exactly the right number of image boxes
    if len(image_boxes) == len(questions_sorted):
        print(f"   ‚úÖ Perfect match! {len(image_boxes)} images for {len(questions_sorted)} questions")
        image_boxes_sorted = sorted(image_boxes, key=lambda b: b['center_y'])
        
        for i, ((_, question_no_str, image_name), box_info) in enumerate(zip(questions_sorted, image_boxes_sorted)):
            x, y, w, h = box_info['box']
            crop = page_cropped[y:y + h, x:x + w]
            
            if not os.path.splitext(image_name)[1]:
                image_name += ".png"
            
            out_path = os.path.join(save_dir, image_name)
            safe_save_image(crop, out_path)
            print(f"   ‚úÖ Q{question_no_str} ‚Üí {image_name} (box {box_info['index']})")
        return True
    
    # If we have more image boxes than questions
    elif len(image_boxes) > len(questions_sorted):
        print(f"   üîç More image boxes ({len(image_boxes)}) than questions ({len(questions_sorted)})")
        
        # Sort by size and position
        image_boxes_sorted = sorted(image_boxes, key=lambda b: (-b['area'], b['center_y']))
        
        # Take top N boxes
        selected_boxes = image_boxes_sorted[:len(questions_sorted)]
        selected_boxes = sorted(selected_boxes, key=lambda b: b['center_y'])
        
        for i, ((_, question_no_str, image_name), box_info) in enumerate(zip(questions_sorted, selected_boxes)):
            x, y, w, h = box_info['box']
            crop = page_cropped[y:y + h, x:x + w]
            
            if not os.path.splitext(image_name)[1]:
                image_name += ".png"
            
            out_path = os.path.join(save_dir, image_name)
            safe_save_image(crop, out_path)
            print(f"   ‚úÖ Q{question_no_str} ‚Üí {image_name} (box {box_info['index']})")
        return True
    
    # If we have fewer image boxes than questions
    else:
        print(f"   ‚ö†Ô∏è  Fewer image boxes ({len(image_boxes)}) than questions ({len(questions_sorted)})")
        
        # Use what we have
        image_boxes_sorted = sorted(image_boxes, key=lambda b: b['center_y'])
        
        for i, box_info in enumerate(image_boxes_sorted):
            if i < len(questions_sorted):
                _, question_no_str, image_name = questions_sorted[i]
                x, y, w, h = box_info['box']
                crop = page_cropped[y:y + h, x:x + w]
                
                if not os.path.splitext(image_name)[1]:
                    image_name += ".png"
                
                out_path = os.path.join(save_dir, image_name)
                safe_save_image(crop, out_path)
                print(f"   ‚úÖ Q{question_no_str} ‚Üí {image_name} (box {box_info['index']})")
        
        return len(image_boxes) > 0

# ======================================
# ‚úÖ LOAD CSV - GROUP BY FILE NAME
# ======================================
file_groups = defaultdict(list)

try:
    with open(CSV_PATH, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        print("\n‚úÖ CSV HEADERS FOUND:", reader.fieldnames)
        
        # folder and file_name are mandatory, sub_folder is optional
        required_fields = ["folder", "file_name", "question_no", "image name"]
        if not all(field in reader.fieldnames for field in required_fields):
            print(f"‚ùå Missing required fields in CSV")
            print(f"   Required: {required_fields}")
            print(f"   Found: {reader.fieldnames}")
            exit(1)

        for row_num, row in enumerate(reader, 1):
            try:
                # Get folder (mandatory)
                folder = row["folder"].strip()
                if not folder:
                    print(f"‚ö†Ô∏è  Row {row_num}: Missing folder")
                    continue
                
                # Get file_name (mandatory, replacing page_no)
                file_name = row["file_name"].strip()
                if not file_name:
                    print(f"‚ö†Ô∏è  Row {row_num}: Missing file_name")
                    continue
                
                # Get sub_folder (optional)
                sub_folder = row.get("sub_folder", "").strip()
                
                # Create key: (folder, sub_folder, file_name)
                # sub_folder can be empty string
                key = (folder, sub_folder, file_name)
                
                question_no = row["question_no"].strip()
                image_name = row["image name"].strip()
                
                # Validate other data
                if not question_no or not image_name:
                    print(f"‚ö†Ô∏è  Row {row_num}: Missing question_no or image name")
                    continue
                    
                # Parse question number using improved function
                question_num = parse_question_number(question_no)
                if question_num == 999 and question_no:
                    print(f"‚ö†Ô∏è  Row {row_num}: Could not parse question number '{question_no}', using 999")
                
                file_groups[key].append((question_num, question_no, image_name))
                
            except Exception as e:
                print(f"‚ùå Error processing row {row_num}: {e}")
                continue

except Exception as e:
    print(f"‚ùå Error reading CSV: {e}")
    traceback.print_exc()
    exit(1)

print(f"\n‚úÖ Loaded {sum(len(v) for v in file_groups.values())} images from CSV")
print(f"‚úÖ Found {len(file_groups)} unique files")

if USE_VISION_API:
    if DEEPSEEK_API_KEY:
        print(f"ü§ñ Vision API: ENABLED (DeepSeek)")
    else:
        print(f"‚ö†Ô∏è  Vision API: DISABLED (No API key provided)")
        USE_VISION_API = False
else:
    print(f"ü§ñ Vision API: DISABLED (Traditional method only)")

# Sort files for consistent processing
sorted_files = sorted(file_groups.items(), key=lambda x: (
    x[0][0],  # folder
    x[0][1],  # subfolder (can be empty)
    x[0][2]   # file_name
))

# ======================================
# ‚úÖ FILE FINDER
# ======================================
def find_file_path(folder, subfolder, file_name):
    """
    Find file with the given name in the folder/subfolder structure.
    subfolder can be empty string.
    """
    # Build path based on whether subfolder is provided
    if subfolder:  # subfolder is not empty
        folder_path = os.path.join(INPUT_ROOT, folder, subfolder)
    else:  # no subfolder
        folder_path = os.path.join(INPUT_ROOT, folder)
    
    if not os.path.isdir(folder_path):
        print(f"‚ùå Folder not found: {folder_path}")
        return None
    
    # Check if file exists directly
    file_path = os.path.join(folder_path, file_name)
    if os.path.exists(file_path):
        return file_path
    
    # Try to find file with different extensions
    base_name = os.path.splitext(file_name)[0]
    files = os.listdir(folder_path)
    
    # Common image extensions to try
    extensions = ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG', '.bmp', '.BMP']
    
    for ext in extensions:
        possible_file = base_name + ext
        if possible_file in files:
            return os.path.join(folder_path, possible_file)
    
    # Try case-insensitive match
    file_lower = file_name.lower()
    for f in files:
        if f.lower() == file_lower:
            return os.path.join(folder_path, f)
    
    # Try matching base name without extension
    for f in files:
        if os.path.splitext(f)[0] == base_name:
            return os.path.join(folder_path, f)
    
    print(f"   üîç File '{file_name}' not found in {folder_path}")
    print(f"   üìÇ Available files: {files[:10]}" + ("..." if len(files) > 10 else ""))
    return None

# ======================================
# ‚úÖ MAIN EXTRACTION WITH ERROR HANDLING
# ======================================
successful_files = 0
failed_files = []
total_images_extracted = 0

for (folder, subfolder, file_name), questions in sorted_files:
    print(f"\n{'='*60}")
    print(f"üìÑ Processing: Folder={folder}, Sub={subfolder or '(none)'}, File={file_name}")
    print(f"   Questions: {[q[1] for q in sorted(questions, key=lambda x: x[0])]}")
    
    try:
        # Find the file
        file_path = find_file_path(folder, subfolder, file_name)
        
        if not file_path:
            print(f"‚ùå File not found")
            failed_files.append((folder, subfolder, file_name, "File not found"))
            continue
        
        # Load the image
        img = cv2.imread(file_path)
        if img is None:
            print(f"‚ùå Failed to load image: {file_path}")
            failed_files.append((folder, subfolder, file_name, "Failed to load image"))
            continue
        
        print(f"   ‚úÖ Loaded file: {os.path.basename(file_path)} ({img.shape[1]}x{img.shape[0]})")
        
        # Create save directory
        if subfolder:
            save_dir = os.path.join(OUTPUT_ROOT, folder, subfolder)
        else:
            save_dir = os.path.join(OUTPUT_ROOT, folder)
        
        # Check for existing files
        existing_count = check_existing_files(save_dir)
        if existing_count > 0:
            print(f"   ‚ö†Ô∏è  Found {existing_count} existing images in {save_dir}")
            
            if BACKUP_BEFORE_OVERWRITE and os.path.exists(save_dir):
                backup_existing_files(save_dir, BACKUP_DIR)
                print(f"   ‚úÖ Existing files backed up")
        
        os.makedirs(save_dir, exist_ok=True)
        
        # Crop header and footer
        page_cropped = crop_header_footer(img)
        H, W = page_cropped.shape[:2]
        print(f"   üìê Cropped size: {W}x{H}")
        
        # Image preprocessing
        gray = cv2.cvtColor(page_cropped, cv2.COLOR_BGR2GRAY)
        
        # Method 1: Adaptive threshold
        th1 = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY_INV,
            17, 3
        )
        
        # Method 2: Canny edges
        edges = cv2.Canny(gray, 60, 160)
        
        # Method 3: Simple threshold
        _, th2 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # Combine methods
        combined = cv2.bitwise_or(th1, edges)
        combined = cv2.bitwise_or(combined, th2)
        
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))
        dilated = cv2.dilate(combined, kernel, iterations=2)
        
        # Find contours
        contours1, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours2, _ = cv2.findContours(dilated, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        
        contours = contours1 if len(contours1) > len(contours2) else contours2
        
        print(f"   üîç Found {len(contours)} contours")
        
        raw_boxes = []
        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            area = w * h
            aspect = w / h if h != 0 else 0
            
            # Check if file_name contains "2" (like page_2.png)
            if "2" in file_name or "page2" in file_name.lower():
                if area > 2000 and 60 < w < 2500 and 60 < h < 1800 and 0.1 < aspect < 10.0:
                    x, y, w, h = pad_box(x, y, w, h, W, H)
                    raw_boxes.append((x, y, w, h))
            else:
                if area > min_area and 80 < w < 2200 and 80 < h < 1600 and 0.15 < aspect < 7.0:
                    x, y, w, h = pad_box(x, y, w, h, W, H)
                    raw_boxes.append((x, y, w, h))
        
        boxes = non_max_suppression(raw_boxes)
        print(f"   üì¶ After NMS: {len(boxes)} boxes")
        
        # Visualize for debugging
        debug_path = visualize_page_detection(page_cropped, boxes, questions, file_name, DEBUG_DIR)
        
        # Extract images using Vision API assistance
        success = extract_images_with_vision_assistance(page_cropped, boxes, questions, save_dir, file_name)
        
        if success:
            successful_files += 1
            print(f"   ‚úÖ File '{file_name}' processed successfully")
        else:
            failed_files.append((folder, subfolder, file_name, "No images extracted"))
            print(f"   ‚ö†Ô∏è  No images extracted from file '{file_name}'")
            
    except Exception as e:
        print(f"‚ùå Error processing file '{file_name}': {e}")
        traceback.print_exc()
        failed_files.append((folder, subfolder, file_name, f"Error: {str(e)}"))

print(f"\n{'='*60}")
print("üéØ EXTRACTION SUMMARY")
print(f"{'='*60}")
print(f"‚úÖ Successful files: {successful_files}/{len(sorted_files)}")
print(f"‚ùå Failed files: {len(failed_files)}")

if BACKUP_BEFORE_OVERWRITE:
    backup_files_count = sum([len(files) for r, d, files in os.walk(BACKUP_DIR)])
    print(f"üì¶ Files backed up: {backup_files_count}")

if failed_files:
    print("\nFailed files:")
    for folder, subfolder, file_name, reason in failed_files:
        subfolder_display = subfolder if subfolder else "(none)"
        print(f"  - {folder}/{subfolder_display}/{file_name}: {reason}")

print(f"\nüìÇ Input folder: {INPUT_ROOT}")
print(f"üìÇ Output base folder: {OUTPUT_ROOT}")
print(f"üêõ Debug visualizations: {DEBUG_DIR}")

if BACKUP_BEFORE_OVERWRITE:
    print(f"üíæ Backup directory: {BACKUP_DIR}")

print(f"\nü§ñ Vision API Status: {'ENABLED' if USE_VISION_API and DEEPSEEK_API_KEY else 'DISABLED'}")

# Clean up cache
if CACHE_VISION_RESULTS:
    print(f"üßπ Vision API cache entries: {len(vision_cache)}")
