import fitz           # PyMuPDF
import cv2
import numpy as np
import os
from PIL import Image
import pytesseract
from pytesseract import Output

# Set this if Tesseract is not in PATH (for Windows)
# Example: r"C:\Program Files\Tesseract-OCR\tesseract.exe"
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# === SETTINGS ===
input_folder = r"C:\Users\menha\Downloads\test11"
output_folder = os.path.join(input_folder, "extracted_diagrams_ocr")
os.makedirs(output_folder, exist_ok=True)

zoom = 3.5   # render zoom for quality (~250 DPI)
base_pad = 15  # base pixel padding
min_area = 3000  # ignore small contours

# === FUNCTIONS ===
def run_ocr_get_label(img):
    """Detect question numbers or option labels via OCR."""
    text_data = pytesseract.image_to_data(img, output_type=Output.DICT)
    text = " ".join(text_data["text"]).upper()
    qnum, option = "", ""

    # Detect question number
    import re
    qmatch = re.search(r"Q\s*(\d+)|QUESTION\s*(\d+)|(\d+)\s*\.", text)
    if qmatch:
        qnum = qmatch.group(1) or qmatch.group(2) or qmatch.group(3)
        qnum = f"Q{qnum}"

    # Detect option
    for ch in ["A", "B", "C", "D"]:
        if f"({ch})" in text or f"{ch}." in text or f"OPTION {ch}" in text:
            option = ch
            break

    # Detect "Answer" or "Ans"
    if "ANSWER" in text or "ANS" in text:
        option = "Answer"

    return qnum, option


def extract_from_pdf(pdf_path):
    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
    pdf_out_dir = os.path.join(output_folder, pdf_name)
    os.makedirs(pdf_out_dir, exist_ok=True)

    doc = fitz.open(pdf_path)
    total_saved = 0
    print(f"\nüìò Processing {pdf_name} ({len(doc)} pages)...")

    for pno in range(len(doc)):
        page = doc[pno]
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        img = np.array(img)[:, :, ::-1].copy()

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        th = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 9)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        boxes = []

        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            area = w * h
            if area < min_area or w < 40 or h < 40:
                continue
            if w > 0.95 * pix.width and h > 0.95 * pix.height:
                continue

            # Expand box adaptively (5‚Äì8%)
            pad_w = int(0.08 * w + base_pad)
            pad_h = int(0.08 * h + base_pad)
            x0 = max(0, x - pad_w)
            y0 = max(0, y - pad_h)
            x1 = min(pix.width, x + w + pad_w)
            y1 = min(pix.height, y + h + pad_h)
            boxes.append((x0, y0, x1, y1))

        # === Sort top-to-bottom, left-to-right ===
        boxes = sorted(boxes, key=lambda b: (b[1] // 100, b[0]))

        for idx, (x0, y0, x1, y1) in enumerate(boxes, start=1):
            crop = img[y0:y1, x0:x1]

            # OCR detection for naming
            qnum, option = run_ocr_get_label(crop)
            qlabel = qnum if qnum else f"P{pno+1}"
            optlabel = f"_{option}" if option else ""
            img_name = f"{pdf_name}_{qlabel}{optlabel}_img{idx:02d}.png"

            cv2.imwrite(os.path.join(pdf_out_dir, img_name), crop)
            total_saved += 1

        print(f"  Page {pno+1}: saved {len(boxes)} diagrams")

    doc.close()
    print(f"‚úÖ Finished {pdf_name}: total {total_saved} diagrams saved.\n")


# === MAIN LOOP ===
pdf_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(".pdf")]
pdf_files.sort()

if not pdf_files:
    print("‚ùå No PDF files found in the folder.")
else:
    for pdf in pdf_files:
        extract_from_pdf(pdf)

print("\nüéâ All PDFs processed successfully!")
print(f"Images saved in: {output_folder}")
