import requests
import base64
import json
import re
from PIL import Image
from io import BytesIO
from google.oauth2 import service_account
from googleapiclient.discovery import build
from typing import Dict, List, Tuple
import time
import concurrent.futures

# ==============================
#  MODEL SETTINGS
# ==============================
EXTRACTION_MODEL = "gpt-4o"        # OCR extraction
ANSWER_MODEL = "gpt-4.1"           # High-accuracy answering
DETECTION_MODEL = "gpt-4o-mini"    # Cheap detection model

EXTRACTION_TEMP = 0.1
ANSWER_TEMP = 0.0
DETECTION_TEMP = 0.0

CONFIDENCE_THRESHOLD = 80          # Not used for fallback anymore (always 4.1)
MAX_ATTEMPTS = 2                   # Try twice if confidence invalid


# ========================================
#  MultiQuestionExtractor
# ========================================
class MultiQuestionExtractor:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

    # --------------------------
    # IMAGE OPTIMIZATION
    # --------------------------
    def optimize_image(self, image_url, target_width=900):
        """Download + resize + convert â†’ base64 JPEG."""
        try:
            response = requests.get(image_url, timeout=30)
            img = Image.open(BytesIO(response.content))

            width, height = img.size
            if width > target_width:
                ratio = target_width / float(width)
                new_height = int(float(height) * ratio)
                img = img.resize((target_width, new_height), Image.Resampling.LANCZOS)

            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')

            output = BytesIO()
            img.save(output, format='JPEG', quality=92, optimize=True)
            return base64.b64encode(output.getvalue()).decode('utf-8')

        except Exception as e:
            print(f"[Image optimization failed] {e}")
            return None

    # --------------------------
    # SMART DETECTION - Check if image contains actual questions
    # --------------------------
    def contains_questions(self, image_url: str, file_name: str) -> bool:
        """Quick check if image contains actual questions (not just references)"""
        base64_image = self.optimize_image(image_url)
        if not base64_image:
            return False

        detection_prompt = """
Does this image contain ACTUAL exam questions starting with question numbers (like Q1, Q2, 1., 2.)? 
Look for complete questions, not just references to question numbers.
Answer ONLY "YES" or "NO".
"""

        payload = {
            "model": DETECTION_MODEL,
            "temperature": DETECTION_TEMP,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": detection_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": "low"  # Low detail for faster/cheaper detection
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 10
        }

        try:
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"].strip().upper()
                return "YES" in content
            return False
        except Exception as e:
            print(f"Detection failed for {file_name}: {e}")
            return False

    # ----------------------------------------------
    # MAIN EXTRACTION: gpt-4o (OCR + question split)
    # ----------------------------------------------
    def extract_all_questions_from_image(self, image_url: str, file_name: str) -> List[Dict]:

        base64_image = self.optimize_image(image_url)
        if not base64_image:
            return [{"error": "Image processing failed", "file_name": file_name}]

        prompt = """
You are an OCR + parsing expert. Extract ALL questions from the exam image.

RULES:
1. Extract each question individually.
2. Detect question type: "MCQ" or "FILL_IN_BLANK".
3. Extract instructions (text BEFORE the first question OR lines beginning with:
   - Instruction(s)
   - Direction(s)
   - Read the following
   - For questions ... etc.)
4. Extract option text A/B/C/D.
5. Detect if question or options contain an image.
6. Convert math/chem formulas to **Unicode text** (NOT LaTeX).
7. Output ONLY a JSON ARRAY (no explanation).

JSON SCHEMA EXAMPLE:
[
  {
    "number": "Q1",
    "type": "MCQ",
    "text": "question text",
    "option_a": "A text",
    "option_b": "B text",
    "option_c": "C text",
    "option_d": "D text",
    "instructions": "common instructions here",
    "has_q_image": false,
    "opt_images": []
  }
]
"""

        payload = {
            "model": EXTRACTION_MODEL,
            "temperature": EXTRACTION_TEMP,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 3500
        }

        try:
            print(f"Extracting questions from: {file_name}")
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=90)

            if response.status_code != 200:
                return [{"error": f"OCR API Error: {response.status_code}", "file_name": file_name}]

            content = response.json()["choices"][0]["message"]["content"].strip()

            # Parse JSON
            questions = self._parse_questions_json(content)
            if not questions:
                print("âš  OCR JSON parsing failed â†’ fallback text parser")
                return self._fallback_parse(content, file_name)

            # Add defaults
            for q in questions:
                q["file_name"] = file_name
                q.setdefault("type", "MCQ")
                q.setdefault("option_a", "")
                q.setdefault("option_b", "")
                q.setdefault("option_c", "")
                q.setdefault("option_d", "")
                q.setdefault("instructions", "")
                q.setdefault("has_q_image", False)
                q.setdefault("opt_images", [])

            return questions

        except Exception as e:
            return [{"error": f"Extraction failed: {e}", "file_name": file_name}]


    # --------------------------
    # JSON PARSER
    # --------------------------
    def _parse_questions_json(self, text):
        text = text.strip()

        # Direct array
        try:
            obj = json.loads(text)
            if isinstance(obj, list):
                return obj
        except:
            pass

        # Code block
        m = re.search(r'```json\s*(\[.*?\])\s*```', text, re.DOTALL)
        if m:
            try:
                return json.loads(m.group(1))
            except:
                pass

        # None found
        return None


    # -----------------------------------
    # FALLBACK TEXT PARSER (simple regex)
    # -----------------------------------
    def _fallback_parse(self, raw_text, file_name):

        lines = raw_text.split("\n")
        questions = []
        current = None
        instructions = []
        question_found = False

        for line in lines:
            t = line.strip()
            if not t:
                continue

            # instructions block BEFORE first question
            if not question_found and re.match(r'(instruction|direction|read)', t, re.I):
                instructions.append(t)
                continue

            # detect question
            qmatch = re.match(r'(Q\.?\s*\d+|\d+\.)', t, re.I)
            if qmatch:
                question_found = True

                if current:
                    current["instructions"] = " ".join(instructions)
                    questions.append(current)

                num = qmatch.group(1)
                txt = t[len(num):].strip()

                current = {
                    "number": num.replace(".", ""),
                    "type": "MCQ",
                    "text": txt,
                    "option_a": "",
                    "option_b": "",
                    "option_c": "",
                    "option_d": "",
                    "instructions": "",
                    "has_q_image": False,
                    "opt_images": [],
                    "file_name": file_name
                }
                continue

            # detect options
            if current:
                om = re.match(r'([A-D])[\.\)]\s*(.+)', t)
                if om:
                    key = f"option_{om.group(1).lower()}"
                    current[key] = om.group(2)
                    continue

                # add to question text
                current["text"] += " " + t

        # last question
        if current:
            current["instructions"] = " ".join(instructions)
            questions.append(current)

        return questions
    # ==========================================
    # ANSWER GENERATION (GPT-4.1)
    # ==========================================
    def analyze_question(self, q: Dict) -> Dict:
        """
        Sequential answering (billing-safe).
        Uses GPT-4.1 for maximum accuracy + confidence scoring.
        """

        qtype = q.get("type", "MCQ")

        if qtype == "FILL_IN_BLANK":
            return self._answer_fill_blank(q)

        else:
            return self._answer_mcq(q)

    # ------------------------------------
    # ANSWER FILL-IN-THE-BLANK
    # ------------------------------------
    def _answer_fill_blank(self, q):
        base_prompt = f"""
You are an exam-solving expert. This is a FILL-IN-THE-BLANK question.

Return ONLY valid JSON.

Question:
{q.get('text','')}

REQUIREMENTS:
- Provide the correct numeric answer
- Give concise step-by-step solution with Unicode math only
- Keep explanations brief but complete
- Confidence score 0-100

JSON FORMAT:
{{
  "correct_answer": "12.5",
  "solution": "concise step-by-step solution with Unicode equations",
  "confidence": 92
}}
"""

        result = self._call_answer_model(base_prompt)

        # force numeric check
        ans = str(result.get("correct_answer", "")).strip()
        if not re.match(r'^[0-9\.\-]+$', ans):
            # retry with strict numeric instruction
            strict_prompt = base_prompt + "\nIMPORTANT: The answer must be strictly numeric."
            result = self._call_answer_model(strict_prompt)

        return result

    # ------------------------------------
    # ANSWER MCQ
    # ------------------------------------
    def _answer_mcq(self, q):
        prompt = f"""
You are an exam-solving expert. Solve the MCQ.

Return ONLY valid JSON.

Question:
{q.get('text','')}

Options:
A: {q.get('option_a','')}
B: {q.get('option_b','')}
C: {q.get('option_c','')}
D: {q.get('option_d','')}

REQUIREMENTS:
- Choose ONLY A, B, C, or D
- Give concise step-by-step solution with Unicode math only
- Keep explanations brief but complete
- Confidence score 0-100

JSON FORMAT:
{{
  "correct_answer": "B",
  "solution": "concise step-by-step solution with Unicode equations",
  "confidence": 88
}}
"""

        return self._call_answer_model(prompt)

    # ------------------------------------
    # CALL GPT-4.1 WITH JSON PARSING
    # ------------------------------------
    def _call_answer_model(self, prompt):
        payload = {
            "model": ANSWER_MODEL,
            "temperature": ANSWER_TEMP,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 450
        }

        try:
            r = requests.post(self.base_url, headers=self.headers, json=payload, timeout=60)
            if r.status_code != 200:
                return {
                    "correct_answer": "Error",
                    "solution": f"API error: {r.status_code}",
                    "confidence": 0
                }

            content = r.json()["choices"][0]["message"]["content"]
            
            # If response is cut off, try one more time with slightly more tokens
            if content.strip().endswith(('}', ']', '"')) == False:
                print("âš  Response appears truncated, retrying with more tokens...")
                payload["max_tokens"] = 550
                r = requests.post(self.base_url, headers=self.headers, json=payload, timeout=60)
                content = r.json()["choices"][0]["message"]["content"]
                
            return self._safe_json(content)

        except Exception as e:
            return {
                "correct_answer": "Error",
                "solution": f"Exception: {e}",
                "confidence": 0
            }

    # ------------------------------------
    # SAFE JSON PARSER FOR ANSWERS
    # ------------------------------------
    def _safe_json(self, text):
        clean = re.sub(r'```json|```', '', text).strip()
        
        # Try to find JSON object with more flexible parsing
        try:
            # First try direct parsing
            return json.loads(clean)
        except:
            pass
        
        try:
            # Try to find JSON object pattern
            match = re.search(r'\{.*\}', clean, re.DOTALL)
            if match:
                return json.loads(match.group())
        except:
            pass
        
        # If all parsing fails, return the raw content in solution field
        return {
            "correct_answer": "",
            "solution": clean,
            "confidence": 0
        }

    # -----------------------------------------------
    # PROCESS IMAGES IN BATCHES (OCR ONLY) - MAINTAINS ORDER
    # -----------------------------------------------
    def process_image_batch(self, image_batch: List[Tuple[str, str]]) -> List[Dict]:
        results = []
        
        # First, detect which images contain actual questions
        print("ðŸ” Detecting images with actual questions...")
        valid_images = []
        
        for name, url in image_batch:
            if self.contains_questions(url, name):
                print(f"âœ… {name} - Contains questions")
                valid_images.append((name, url))
            else:
                print(f"â­ï¸ {name} - No questions found (skipping)")
        
        if not valid_images:
            return results
            
        # Process only images with actual questions
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # Submit all tasks and store them in order
            future_to_index = {
                executor.submit(self.extract_all_questions_from_image, url, name): i 
                for i, (name, url) in enumerate(valid_images)
            }
            
            # Create a list to store results in original order
            temp_results = [None] * len(valid_images)
            
            for future in concurrent.futures.as_completed(future_to_index):
                index = future_to_index[future]
                fname, url = valid_images[index]
                try:
                    res = future.result()
                    temp_results[index] = res
                except Exception as e:
                    temp_results[index] = [{"error": str(e), "file_name": fname}]
            
            # Flatten the results while maintaining order
            for result in temp_results:
                if result is not None:
                    results.extend(result)
        
        return results

    # -----------------------------------------------
    # GET ANSWERS SEQUENTIALLY USING GPT-4.1
    # -----------------------------------------------
    def get_answers_sequential(self, questions: List[Dict]) -> List[Dict]:
        output = []

        for q in questions:
            if "error" in q:
                output.append(q)
                continue

            ans = self.analyze_question(q)
            combined = {**q, **ans}
            output.append(combined)

            time.sleep(1.0)

        return output


# =====================================================
#  GOOGLE SHEET PROCESSOR
# =====================================================
class GoogleSheetProcessor:
    def __init__(self, credentials_file: str, sheet_id: str, api_key: str, sheet_tab: str):
        self.sheet_id = sheet_id
        self.sheet_tab = sheet_tab
        self.extractor = MultiQuestionExtractor(api_key)
        self.service = self._auth(credentials_file)

    # ----------------------
    # AUTH
    # ----------------------
    def _auth(self, credentials_file):
        try:
            scopes = ['https://www.googleapis.com/auth/spreadsheets']
            creds = service_account.Credentials.from_service_account_file(
                credentials_file, scopes=scopes)
            return build('sheets', 'v4', credentials=creds)
        except Exception as e:
            print("Google Sheets Auth Failed:", e)
            raise

    # ----------------------
    # READ SHEET
    # ----------------------
    def read_sheet(self):
        try:
            result = self.service.spreadsheets().values().get(
                spreadsheetId=self.sheet_id,
                range=f"{self.sheet_tab}!A:Q"  # Read all columns to check progress
            ).execute()

            return result.get("values", [])
        except Exception as e:
            print("Error reading sheet:", e)
            return []

    # ----------------------
    # CHECK EXISTING PROGRESS
    # ----------------------
    def check_existing_progress(self, data):
        """Check which files have already been processed"""
        processed_files = set()
        if len(data) > 1:  # Has header + at least one row
            for row in data[1:]:
                if len(row) >= 15:  # Has data up to confidence column
                    file_name = row[0] if row else ""
                    if file_name and file_name != "ERROR":
                        processed_files.add(file_name)
        return processed_files

    # ----------------------
    # CLEAR OUTPUT COLUMNS (OPTIONAL - now only for full reset)
    # ----------------------
    def clear_output(self):
        try:
            self.service.spreadsheets().values().clear(
                spreadsheetId=self.sheet_id,
                range=f"{self.sheet_tab}!C:Q"
            ).execute()
            print("Old data cleared (C:Q).")
        except Exception as e:
            print("Clear failed:", e)

    # ----------------------
    # UPDATE SHEET
    # ----------------------
    def update_sheet(self, rows: List[List], start_row: int = 2):
        try:
            self.service.spreadsheets().values().update(
                spreadsheetId=self.sheet_id,
                range=f"{self.sheet_tab}!C{start_row}",
                valueInputOption="RAW",
                body={"values": rows}
            ).execute()
            print(f"Sheet updated successfully from row {start_row}.")
        except Exception as e:
            print("Update failed:", e)

    # =====================================================
    # PROCESS ALL IMAGES WITH RESUME CAPABILITY
    # =====================================================
    def process_all_images(self, batch_size=3, resume=True):

        data = self.read_sheet()

        if len(data) < 2:
            print("No data in sheet.")
            return

        # Check existing progress if resuming
        processed_files = set()
        if resume:
            processed_files = self.check_existing_progress(data)
            if processed_files:
                print(f"ðŸ“Š Resuming - Found {len(processed_files)} already processed files")
            else:
                print("ðŸ†• Starting fresh - No previous progress found")

        # Don't clear output if resuming
        if not resume or not processed_files:
            self.clear_output()

        # build batches, skip already processed files
        batches = []
        temp = []
        processed_count = 0

        for i, row in enumerate(data[1:], start=2):
            if len(row) < 2:
                continue

            fname = row[0]
            url = row[1]

            if not url.startswith("http"):
                continue

            # Skip already processed files when resuming
            if resume and fname in processed_files:
                processed_count += 1
                continue

            temp.append((fname, url))

            if len(temp) == batch_size:
                batches.append(temp)
                temp = []

        if temp:
            batches.append(temp)

        print(f"ðŸ“ Total files to check: {sum(len(b) for b in batches)}")
        print(f"âœ… Already processed: {processed_count}")

        if not batches:
            print("ðŸŽ‰ All files already processed!")
            return

        # process batches
        all_questions = []

        for i, b in enumerate(batches, start=1):
            print(f"\n=== Processing batch {i}/{len(batches)} ===")
            qlist = self.extractor.process_image_batch(b)

            # remove OCR errors
            clean_q = [q for q in qlist if "error" not in q]
            err_q = [q for q in qlist if "error" in q]

            if clean_q:
                print(f"Solving {len(clean_q)} questions...")
                solved = self.extractor.get_answers_sequential(clean_q)
                all_questions.extend(solved)

            all_questions.extend(err_q)

            time.sleep(3)

        # format sheet rows
        rows = []

        for q in all_questions:
            if "error" in q:
                rows.append([
                    q.get("file_name",""), "ERROR", "", q["error"], "", "", "", "", 
                    "", "", "", "", "", "", "0"
                ])
                continue

            rows.append([
                q.get("file_name",""),
                q.get("type",""),
                q.get("number",""),
                q.get("text",""),
                q.get("option_a",""),
                q.get("option_b",""),
                q.get("option_c",""),
                q.get("option_d",""),
                "Yes" if q.get("has_q_image") else "No",
                ",".join(q.get("opt_images",[])),
                "Yes" if q.get("instructions") else "No",
                q.get("instructions",""),
                q.get("correct_answer",""),
                q.get("solution",""),
                q.get("confidence",0)
            ])

        # Find the next empty row for appending
        next_row = len(data) + 1 if data else 2
        
        self.update_sheet(rows, next_row)

# =====================================================
# MAIN RUNNER
# =====================================================

def main():

    # ====== IMPORTANT CONFIGURATION ======
    OPENAI_API_KEY = "your_openai_api_key_here"

    if not OPENAI_API_KEY or OPENAI_API_KEY == "your_openai_api_key_here":
        print("âŒ ERROR: Please put your real OpenAI API key in the script.")
        return

    GOOGLE_SHEET_ID = "1U6gW0yqh3GZlkyxvhF_5k3sXMP8GwZT-TNsXqKv7S1o"
    CREDENTIALS_FILE = "service-account.json"
    SHEET_TAB = "Sheet4"

    BATCH_SIZE = 3            # OCR images per batch
    RESUME_MODE = True        # Set to False to start from scratch

    print("\n" + "="*80)
    print(" ðŸ” HIGH-ACCURACY EXAM EXTRACTION + SOLUTION SCRIPT ")
    print("="*80)
    print(f" Extraction Model : {EXTRACTION_MODEL}")
    print(f" Answer Model     : {ANSWER_MODEL}")
    print(f" Detection Model  : {DETECTION_MODEL}")
    print(f" Batch Size       : {BATCH_SIZE}")
    print(f" Resume Mode      : {'ON' if RESUME_MODE else 'OFF'}")
    print("="*80)

    try:
        processor = GoogleSheetProcessor(
            CREDENTIALS_FILE,
            GOOGLE_SHEET_ID,
            OPENAI_API_KEY,
            SHEET_TAB
        )

        processor.process_all_images(batch_size=BATCH_SIZE, resume=RESUME_MODE)

        print("\nðŸŽ‰ COMPLETED SUCCESSFULLY!")
        print("All results saved to sheet columns C through Q.")

    except Exception as e:
        print("\nâŒ FATAL ERROR:", e)


# =====================================================
# ENTRY POINT
# =====================================================
if __name__ == "__main__":
    main()
